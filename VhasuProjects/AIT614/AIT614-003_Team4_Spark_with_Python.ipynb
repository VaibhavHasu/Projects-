{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a562f6c-72e5-46d0-98b1-4e59786e529b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### AIT 614 - Big Data Essentials <br>\n",
    "#### Project Title: FHWA Bridge Conditions Analysis Using Big Data Techniques\n",
    "#### 1. Spark with Python\n",
    "#### TEAM 4\n",
    "<hr>\n",
    "\n",
    "Course Section #: AIT 614 - 003 <br>\n",
    "#### Team Members\n",
    "1. Aryan Patel Kolagani - G01517560 <br>\n",
    "2. Rithvik Madhavaram - G01501806 <br>\n",
    "3. Chetan Muppavarapu - G01504057 <br>\n",
    "4. Srivaths Nrusimha Rao Chengal - G01512113 <br>\n",
    "5. Vaibhav Hasu - G01517039 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b76cba44-fff3-4d90-b996-dbf253e3f550",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------+--------------+-------------+------------------+\n|Bridge_ID| Material|Age_Years|Deck_Condition|Daily_Traffic|   Repair_Cost_USD|\n+---------+---------+---------+--------------+-------------+------------------+\n|   100000|    Steel|     17.0|           6.0|      12899.0| 4315877.039064087|\n|   100001|Composite|     52.0|           6.0|      47458.0|1881782.6492399995|\n|   100002|Composite|     35.0|           3.0|      68505.0|3648371.4340184284|\n|   100003|   Timber|     60.0|           4.0|      10563.0|1828414.1550813331|\n|   100004|  Masonry|     90.0|           8.0|     157293.0|1867925.1355395797|\n|   100005|    Steel|     76.0|           6.0|      99947.0| 2699402.113745118|\n|   100006|   Timber|     25.0|           8.0|       9686.0|1496286.4476785637|\n|   100007|    Steel|     86.0|           5.0|     133008.0|1959640.3036547482|\n|   100008|Composite|     20.0|           4.0|     177541.0|3547937.3828598824|\n|   100009| Concrete|     81.0|           6.0|      86149.0| 4855250.842519514|\n+---------+---------+---------+--------------+-------------+------------------+\nonly showing top 10 rows\n\n+--------------+-----+\n|Deck_Condition|count|\n+--------------+-----+\n|           3.0|  801|\n|           4.0|  848|\n|           5.0|  827|\n|           6.0|  826|\n|           7.0|  873|\n|           8.0|  825|\n+--------------+-----+\n\n+---------+--------------------+\n| Material|avg(Repair_Cost_USD)|\n+---------+--------------------+\n|Composite|  2489652.4670429737|\n| Concrete|   2465160.720160519|\n|  Masonry|  2572516.6053956985|\n|    Steel|  2480757.5698571126|\n|   Timber|  2555421.4270824236|\n+---------+--------------------+\n\n+---------+---------+---------+--------------+\n|Bridge_ID| Material|Age_Years|Deck_Condition|\n+---------+---------+---------+--------------+\n|   100463|  Masonry|     99.0|           4.0|\n|   100133|    Steel|     99.0|           3.0|\n|   100713| Concrete|     99.0|           3.0|\n|   100959|Composite|     99.0|           4.0|\n|   100963|Composite|     99.0|           4.0|\n|   101378|   Timber|     99.0|           4.0|\n|   101461|    Steel|     99.0|           3.0|\n|   102147|   Timber|     99.0|           4.0|\n|   102216| Concrete|     99.0|           4.0|\n|   102488|    Steel|     99.0|           3.0|\n+---------+---------+---------+--------------+\nonly showing top 10 rows\n\n+---------+-----+-------------+--------------+\n|Bridge_ID|State|Daily_Traffic|Deck_Condition|\n+---------+-----+-------------+--------------+\n|   103507|   PA|     199978.0|           8.0|\n|   103268|   NC|     199973.0|           8.0|\n|   100057|   MI|     199858.0|           8.0|\n|   103937|   TX|     199852.0|           4.0|\n|   103853|   NC|     199846.0|           6.0|\n|   104090|   TX|     199782.0|           3.0|\n|   100297|   CA|     199720.0|           3.0|\n|   100573|   IL|     199713.0|           6.0|\n|   101778|   TX|     199701.0|           7.0|\n|   103966|   FL|     199621.0|           5.0|\n+---------+-----+-------------+--------------+\nonly showing top 10 rows\n\nroot\n |-- Bridge_ID: string (nullable = true)\n |-- State: string (nullable = true)\n |-- Latitude: string (nullable = true)\n |-- Longitude: string (nullable = true)\n |-- Material: string (nullable = true)\n |-- Lanes: string (nullable = true)\n |-- Superstructure_Condition: string (nullable = true)\n |-- Substructure_Condition: string (nullable = true)\n |-- Avg_Annual_Temp_C: string (nullable = true)\n |-- Avg_Annual_Precipitation_mm: string (nullable = true)\n |-- Last_Inspection_Year: string (nullable = true)\n |-- Repair_Cost_USD: double (nullable = true)\n |-- Deck_Condition: double (nullable = true)\n |-- Daily_Traffic: double (nullable = true)\n |-- Age_Years: double (nullable = true)\n |-- Deterioration_Rate: double (nullable = true)\n |-- Failure_Probability: double (nullable = true)\n |-- Truck_Percentage: double (nullable = true)\n |-- Repair_Time_Days: double (nullable = true)\n |-- Length_Meters: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, regexp_replace\n",
    "\n",
    "\n",
    "\n",
    "# Loading the dataset from DBFS\n",
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"dbfs:/FileStore/shared_uploads/akolagan@gmu.edu/FHWA_Bridge_Conditions_Dataset.csv\")\n",
    "\n",
    "# Cleaning non-numeric columns (remove $ and , and convert to numeric)\n",
    "columns_to_clean = [\n",
    "    \"Repair_Cost_USD\", \"Deck_Condition\", \"Daily_Traffic\", \"Age_Years\",\n",
    "    \"Deterioration_Rate\", \"Failure_Probability\", \"Truck_Percentage\",\n",
    "    \"Repair_Time_Days\", \"Length_Meters\"\n",
    "]\n",
    "\n",
    "# Apply cleaning and cast to double\n",
    "for col_name in columns_to_clean:\n",
    "    df = df.withColumn(f\"{col_name}_clean\", regexp_replace(col(col_name), \"[$,%]\", \"\"))\n",
    "    df = df.withColumn(f\"{col_name}_clean\", col(f\"{col_name}_clean\").cast(\"double\"))\n",
    "\n",
    "# Droping rows with nulls in key columns\n",
    "df_clean = df.dropna(subset=[\n",
    "    \"Deck_Condition_clean\", \"Daily_Traffic_clean\", \"Age_Years_clean\", \"Repair_Cost_USD_clean\"\n",
    "])\n",
    "\n",
    "# Droping original versions of conflicting columns before renaming\n",
    "df_clean = df_clean.drop(\"Age_Years\", \"Deck_Condition\", \"Daily_Traffic\", \"Repair_Cost_USD\",\n",
    "                         \"Deterioration_Rate\", \"Failure_Probability\", \"Truck_Percentage\", \n",
    "                         \"Repair_Time_Days\", \"Length_Meters\")\n",
    "\n",
    "# Renaming cleaned columns to final names\n",
    "df_clean = df_clean \\\n",
    "    .withColumnRenamed(\"Deck_Condition_clean\", \"Deck_Condition\") \\\n",
    "    .withColumnRenamed(\"Daily_Traffic_clean\", \"Daily_Traffic\") \\\n",
    "    .withColumnRenamed(\"Age_Years_clean\", \"Age_Years\") \\\n",
    "    .withColumnRenamed(\"Repair_Cost_USD_clean\", \"Repair_Cost_USD\") \\\n",
    "    .withColumnRenamed(\"Deterioration_Rate_clean\", \"Deterioration_Rate\") \\\n",
    "    .withColumnRenamed(\"Failure_Probability_clean\", \"Failure_Probability\") \\\n",
    "    .withColumnRenamed(\"Truck_Percentage_clean\", \"Truck_Percentage\") \\\n",
    "    .withColumnRenamed(\"Repair_Time_Days_clean\", \"Repair_Time_Days\") \\\n",
    "    .withColumnRenamed(\"Length_Meters_clean\", \"Length_Meters\")\n",
    "\n",
    "# Exploratory Data Queries\n",
    "\n",
    "# a. Sample of cleaned dataset\n",
    "df_clean.select(\"Bridge_ID\", \"Material\", \"Age_Years\", \"Deck_Condition\", \"Daily_Traffic\", \"Repair_Cost_USD\").show(10)\n",
    "\n",
    "# b. Count of bridges by Deck Condition\n",
    "df_clean.groupBy(\"Deck_Condition\").count().orderBy(\"Deck_Condition\").show()\n",
    "\n",
    "# c. Average Repair Cost by Material\n",
    "df_clean.groupBy(\"Material\").avg(\"Repair_Cost_USD\").orderBy(\"Material\").show()\n",
    "\n",
    "# d. Bridges older than 60 years with poor Deck Condition\n",
    "df_clean.filter((col(\"Age_Years\") > 60) & (col(\"Deck_Condition\") <= 4)) \\\n",
    "    .select(\"Bridge_ID\", \"Material\", \"Age_Years\", \"Deck_Condition\") \\\n",
    "    .orderBy(\"Age_Years\", ascending=False).show(10)\n",
    "\n",
    "# e. Top 10 bridges by Daily Traffic\n",
    "df_clean.orderBy(col(\"Daily_Traffic\").desc()) \\\n",
    "    .select(\"Bridge_ID\", \"State\", \"Daily_Traffic\", \"Deck_Condition\").show(10)\n",
    "\n",
    "# Saving cleaned dataset to DBFS for reuse by ML and dashboard teams\n",
    "df_clean.write.mode(\"overwrite\").csv(\"/dbfs/FileStore/cleaned_fhwa_bridge_data.csv\", header=True)\n",
    "\n",
    "# Printing schema to verify final structure\n",
    "df_clean.printSchema()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "AIT614-003_Team4_Spark_with_Python",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}